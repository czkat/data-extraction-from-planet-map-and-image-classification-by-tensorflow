{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from local directory\n",
    "data_dir = '/home/zheng/Desktop/crisp/cut_sub/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 4 classes.\n",
      "Using 800 files for training.\n",
      "Found 1000 files belonging to 4 classes.\n",
      "Using 200 files for validation.\n",
      "['cloud', 'developed', 'green', 'water']\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "batch_size = 50\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "\n",
    "# create training set\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# create validation set\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# check class names\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale image to 0-1\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "# optimize for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fade456d440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fade456d440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2652 - accuracy: 0.3123WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fade458d200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fade458d200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 1.2619 - accuracy: 0.3143 - val_loss: 0.9264 - val_accuracy: 0.6500\n",
      "Epoch 2/16\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 0.8448 - accuracy: 0.7020 - val_loss: 0.3534 - val_accuracy: 0.9350\n",
      "Epoch 3/16\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 0.2700 - accuracy: 0.9253 - val_loss: 0.1666 - val_accuracy: 0.9550\n",
      "Epoch 4/16\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1837 - accuracy: 0.9245 - val_loss: 0.1366 - val_accuracy: 0.9550\n",
      "Epoch 5/16\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 0.0884 - accuracy: 0.9667 - val_loss: 0.0927 - val_accuracy: 0.9650\n",
      "Epoch 6/16\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 0.0746 - accuracy: 0.9677 - val_loss: 0.0634 - val_accuracy: 0.9800\n",
      "Epoch 7/16\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 0.1192 - accuracy: 0.9579 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
      "Epoch 8/16\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 0.0892 - accuracy: 0.9650 - val_loss: 0.1357 - val_accuracy: 0.9300\n",
      "Epoch 9/16\n",
      "16/16 [==============================] - 2s 106ms/step - loss: 0.0889 - accuracy: 0.9623 - val_loss: 0.1823 - val_accuracy: 0.9050\n",
      "Epoch 10/16\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0730 - accuracy: 0.9742 - val_loss: 0.1740 - val_accuracy: 0.9050\n",
      "Epoch 11/16\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.0817 - accuracy: 0.9644 - val_loss: 0.2200 - val_accuracy: 0.8900\n",
      "Epoch 12/16\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0914 - accuracy: 0.9582 - val_loss: 0.2295 - val_accuracy: 0.9150\n",
      "Epoch 13/16\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.0996 - accuracy: 0.9615 - val_loss: 0.5480 - val_accuracy: 0.8000\n",
      "Epoch 14/16\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1194 - accuracy: 0.9543 - val_loss: 0.0758 - val_accuracy: 0.9750\n",
      "Epoch 15/16\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 0.1465 - accuracy: 0.9292 - val_loss: 0.0511 - val_accuracy: 0.9900\n",
      "Epoch 16/16\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 0.1073 - accuracy: 0.9699 - val_loss: 0.0395 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fade46a4650>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "num_classes = 4\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_9 (Rescaling)      (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 167,492\n",
      "Trainable params: 167,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
